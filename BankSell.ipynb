{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisseDB/MachineLearning-BankAnalyses/blob/main/BankSell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "j_egWT9cnXTr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import mean_absolute_error, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# If you would like to make further imports from Tensorflow, add them here\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Data Balancing\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEOxKS8_jtmw",
        "outputId": "40f5f7f3-d96f-4080-c5b2-0cb7102ce0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oef-y2gVlAuf",
        "outputId": "cd8bb7b1-0b52-42d4-e366-7ea1a35c756d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BankData\n"
          ]
        }
      ],
      "source": [
        "# /content/drive/MyDrive/BankData/bank-full.csv\n",
        "%cd \"/content/drive/MyDrive/BankData\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "33xFd8V6Y5mD"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K0g3ErrNhNP"
      },
      "source": [
        "**OBTENER EL DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVBtnHQVuiYi"
      },
      "source": [
        "Cargar mi dataset y dividirlo para lo que usaremos para el test y el train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "LvJiSuFcnVpV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"bank-full.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdqbxJqNusIT"
      },
      "source": [
        "*Limpiar los datos*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiJgB7EELISp"
      },
      "source": [
        "Seleccionar columnas que usaremos para el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "NQW4umpxLMp4"
      },
      "outputs": [],
      "source": [
        "columnas = ['age', 'marital', 'education', 'default', 'loan', 'duration', 'y']\n",
        "df_columnas_seleccionadas = df[columnas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gOcEHw8uzvO",
        "outputId": "c4c5fbf7-7ba9-4e49-98a2-f8446f16790d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43354, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "df_columnas_seleccionadas = df_columnas_seleccionadas[df_columnas_seleccionadas['education'] != 'unknown']\n",
        "df_columnas_seleccionadas.reset_index(drop=True, inplace=True)\n",
        "df_columnas_seleccionadas.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TU6dKegNVft"
      },
      "source": [
        "**SEPARACIÓN DEL SET DE PRUEBA Y DEL SET DE TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooEOrtZ6w4tt"
      },
      "source": [
        "Ya que lo limpiamos, ahora si dividimos el data set para tener el conjunto que sera entrenado y el conjunto que sera para pruebas (train_data y test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "khewd8cxxAj1"
      },
      "outputs": [],
      "source": [
        "train_data = df_columnas_seleccionadas.iloc[:34000]\n",
        "test_data = df_columnas_seleccionadas.iloc[34000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiCjqpW046_X"
      },
      "source": [
        "Como queremos estudiar si contrataran o no la tarjeta, y ese dato viene en la columna Y, debemos quitar esa información de nuestros fragmentos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "JXRju1PB43Ug"
      },
      "outputs": [],
      "source": [
        "test_labels_target = test_data[\"y\"]\n",
        "test_data = test_data.drop(columns=[\"y\"])\n",
        "train_labels_target = train_data[\"y\"]\n",
        "train_data = train_data.drop(columns=[\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nilcxh5INMhi"
      },
      "source": [
        "**PREPROCESADO DEL TARGET**\n",
        "*Label Encoder*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhYBoxVRMyh6"
      },
      "source": [
        "Como el modelo solo acepta números, debemos pasar mi target a binario, para eso usaremos Label encoder, ya que:\n",
        "\n",
        "*   Solo tenemos dos categorias (yes / no)\n",
        "*   Al tener solo dos categorias, no hay problema confusión de orde\n",
        "*   Usa menos memoria\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "i4ZbzBEHdv4z"
      },
      "outputs": [],
      "source": [
        "enc = LabelEncoder()\n",
        "train_labels_target = enc.fit_transform(train_labels_target)\n",
        "test_labels_target = enc.transform(test_labels_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQ49umbpScZ"
      },
      "source": [
        "**PREPROCESADO DE FEATURES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1Noe61l6cHN"
      },
      "source": [
        "Usamos OneHotEncoder ya que tenemos mas de dos categorias, nos guiamos con \"Titanic Solution One-Hot-Encode All The Things\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "eMkvIoOFslb8"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot encoder to each column with categorical data\n",
        "object_cols = train_data.select_dtypes(include='object').columns\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "OH_encoder.fit(train_data[object_cols])\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.transform(train_data[object_cols]))\n",
        "joblib.dump(OH_encoder, '/content/drive/MyDrive/BankData/onehotencoder.pkl')\n",
        "OH_cols_test = pd.DataFrame(OH_encoder.transform(test_data[object_cols]))\n",
        "\n",
        "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
        "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = train_data.index\n",
        "OH_cols_test.index = test_data.index\n",
        "\n",
        "# Add one-hot encoded columns to numerical features (age - duration)\n",
        "numeric_columns = train_data.drop(columns=object_cols).columns\n",
        "numeric_train = train_data[numeric_columns]\n",
        "numeric_test = test_data[numeric_columns]\n",
        "\n",
        "train_data = pd.concat([OH_cols_train, numeric_train], axis=1)\n",
        "test_data = pd.concat([OH_cols_test, numeric_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDmAFPEpoaU4"
      },
      "source": [
        "**Construir el modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ2xbas0cvlB"
      },
      "source": [
        "Dropout nos ayuda a evitar que el modelo se aprenda de memoria los datos de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "aja9ftOSeF2f"
      },
      "outputs": [],
      "source": [
        "def get_model_simple(input_shape):\n",
        "    model  =  Sequential([\n",
        "                    Flatten(input_shape=input_shape),\n",
        "                    # las capas del modelo\n",
        "                    Dense(256, activation='relu'),\n",
        "                    Dropout(0.3),\n",
        "                    Dense(256, activation='relu'),\n",
        "                    Dropout(0.4),\n",
        "                    Dense(128, activation='relu'),\n",
        "                    Dropout(0.4),\n",
        "                    Dense(64, activation='relu'),\n",
        "                    Dropout(0.3),\n",
        "                    # solo necesitamos una neurona de salida cuando trabajamos con binario\n",
        "                    Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfddaIN_b04Q"
      },
      "source": [
        "Learning Rate = que tan rqapido cambian los pesos, entre mas cercano a 1, mas rapido es el cambio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "D9cMMloTad3v"
      },
      "outputs": [],
      "source": [
        "#0.001 de acuerdo al paper\n",
        "optimizer = Adam(learning_rate=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "_NJ9XvxDCqIL"
      },
      "outputs": [],
      "source": [
        "# pasamos los hiperparametros y configurar la red\n",
        "def compile_model_simple(model):\n",
        "    # loss = diferencia entre las predicciones de un modelo\n",
        "    model.compile(optimizer= optimizer, loss = \"binary_crossentropy\", metrics=['accuracy',\n",
        "                                                                            tf.keras.metrics.Precision(name=\"precision\"),\n",
        "                                                                            tf.keras.metrics.Recall(name=\"recall\"),\n",
        "                                                                           ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3gE4AiuA4Ey"
      },
      "source": [
        "\n",
        "\n",
        "* train_data son los datos que usaremos para el entrenamiento\n",
        "* train_labels_target para que voy a entrenar mis train_data\n",
        "* epochs las epocas para saber cuantas veces le voy a dar la vuelta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "eW5TJBrs9flm"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_data, train_labels_target):\n",
        "    history = model.fit(train_data, train_labels_target, epochs=250, batch_size=64, class_weight=class_weights, validation_data=(test_data, test_labels_target))\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzA5xc462Qnw"
      },
      "source": [
        "**BALANCEO DE DATOS USANDO K-MEANS SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "c3Zna4mK11HK"
      },
      "outputs": [],
      "source": [
        "# print(f\"The number of classes before fit: {Counter(train_labels_target)}\")\n",
        "# kms = KMeansSMOTE(random_state=42)\n",
        "# train_data, train_labels_target = kms.fit_resample(train_data, train_labels_target)\n",
        "# print(f\"The number of classes after fit: {Counter(train_labels_target)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "zacJpeo2tjN-"
      },
      "outputs": [],
      "source": [
        "# print(f\"The number of classes before fit: {Counter(train_labels_target)}\")\n",
        "# sm = SMOTE(random_state=2)\n",
        "# train_data, train_labels_target = sm.fit_resample(train_data, train_labels_target)\n",
        "# print(f\"The number of classes after fit: {Counter(train_labels_target)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OafYz4c80rsP"
      },
      "source": [
        "*Después de dos intentos fallidos, el oversample no estaba siendo la mejor opcion, por lo tanto, haremos oversample y undersample*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1qLKWj8ARtT",
        "outputId": "a208bee5-a6c0-466a-eac3-39a07d475800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of classes after fit: Counter({np.int64(1): 15000, np.int64(0): 12000})\n"
          ]
        }
      ],
      "source": [
        "pipline = Pipeline([\n",
        "    ('oversample', SMOTE(sampling_strategy={1: 15000}, random_state=42)),\n",
        "    ('undersample', RandomUnderSampler(sampling_strategy={0: 12000, 1: 15000}, random_state=42))\n",
        "])\n",
        "\n",
        "train_data, train_labels_target = pipline.fit_resample(train_data, train_labels_target)\n",
        "print(f\"The number of classes after fit: {Counter(train_labels_target)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPtCC4NIEhiM"
      },
      "source": [
        "Evitemos que el modelo ignore a la clase minoritaria, decirle al modelo, cuando le va a doler equivocarse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "qc2HFTWBDAcn"
      },
      "outputs": [],
      "source": [
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels_target), y=train_labels_target)\n",
        "class_weights = dict(enumerate(weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U6-ZUfuBa47"
      },
      "source": [
        "* Obtenemos el modelo, entre mas parametros es mas poderoso el modelo, sin embargo, será mas pesado\n",
        "* Con summary vemos el modelo completo para despues compilarlo\n",
        "* Hacemos el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ahx4aDai_GN8",
        "outputId": "83a48604-9225-468f-c865-a9c190d31194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m3,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,337\u001b[0m (431.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,337</span> (431.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,337\u001b[0m (431.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,337</span> (431.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 4.3254 - precision: 0.6108 - recall: 0.7522 - val_accuracy: 0.7297 - val_loss: 0.5444 - val_precision: 0.6598 - val_recall: 0.1534\n",
            "Epoch 2/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6956 - loss: 0.6843 - precision: 0.7182 - recall: 0.7397 - val_accuracy: 0.7333 - val_loss: 0.5474 - val_precision: 0.6372 - val_recall: 0.2007\n",
            "Epoch 3/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7430 - loss: 0.5515 - precision: 0.7801 - recall: 0.7449 - val_accuracy: 0.7289 - val_loss: 0.5408 - val_precision: 0.6678 - val_recall: 0.1421\n",
            "Epoch 4/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7608 - loss: 0.5178 - precision: 0.8108 - recall: 0.7397 - val_accuracy: 0.7298 - val_loss: 0.5356 - val_precision: 0.6564 - val_recall: 0.1567\n",
            "Epoch 5/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7718 - loss: 0.5060 - precision: 0.8249 - recall: 0.7453 - val_accuracy: 0.7359 - val_loss: 0.5304 - val_precision: 0.6203 - val_recall: 0.2464\n",
            "Epoch 6/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7778 - loss: 0.4995 - precision: 0.8355 - recall: 0.7446 - val_accuracy: 0.7359 - val_loss: 0.5258 - val_precision: 0.6320 - val_recall: 0.2289\n",
            "Epoch 7/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.4888 - precision: 0.8407 - recall: 0.7493 - val_accuracy: 0.7367 - val_loss: 0.5293 - val_precision: 0.6216 - val_recall: 0.2508\n",
            "Epoch 8/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7816 - loss: 0.4865 - precision: 0.8404 - recall: 0.7464 - val_accuracy: 0.7368 - val_loss: 0.5262 - val_precision: 0.6265 - val_recall: 0.2439\n",
            "Epoch 9/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7850 - loss: 0.4817 - precision: 0.8472 - recall: 0.7455 - val_accuracy: 0.7363 - val_loss: 0.5241 - val_precision: 0.6124 - val_recall: 0.2633\n",
            "Epoch 10/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7845 - loss: 0.4801 - precision: 0.8445 - recall: 0.7477 - val_accuracy: 0.7374 - val_loss: 0.5213 - val_precision: 0.6049 - val_recall: 0.2904\n",
            "Epoch 11/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7881 - loss: 0.4762 - precision: 0.8497 - recall: 0.7492 - val_accuracy: 0.7374 - val_loss: 0.5237 - val_precision: 0.6085 - val_recall: 0.2823\n",
            "Epoch 12/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7875 - loss: 0.4719 - precision: 0.8443 - recall: 0.7547 - val_accuracy: 0.7357 - val_loss: 0.5221 - val_precision: 0.5905 - val_recall: 0.3094\n",
            "Epoch 13/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7897 - loss: 0.4709 - precision: 0.8460 - recall: 0.7573 - val_accuracy: 0.7374 - val_loss: 0.5224 - val_precision: 0.6080 - val_recall: 0.2834\n",
            "Epoch 14/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7906 - loss: 0.4692 - precision: 0.8534 - recall: 0.7499 - val_accuracy: 0.7364 - val_loss: 0.5221 - val_precision: 0.5906 - val_recall: 0.3164\n",
            "Epoch 15/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.4678 - precision: 0.8442 - recall: 0.7550 - val_accuracy: 0.7377 - val_loss: 0.5199 - val_precision: 0.6004 - val_recall: 0.3032\n",
            "Epoch 16/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7925 - loss: 0.4640 - precision: 0.8490 - recall: 0.7596 - val_accuracy: 0.7367 - val_loss: 0.5208 - val_precision: 0.5866 - val_recall: 0.3325\n",
            "Epoch 17/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7926 - loss: 0.4640 - precision: 0.8513 - recall: 0.7569 - val_accuracy: 0.7379 - val_loss: 0.5176 - val_precision: 0.5955 - val_recall: 0.3186\n",
            "Epoch 18/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7924 - loss: 0.4586 - precision: 0.8501 - recall: 0.7579 - val_accuracy: 0.7371 - val_loss: 0.5208 - val_precision: 0.5877 - val_recall: 0.3336\n",
            "Epoch 19/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7943 - loss: 0.4587 - precision: 0.8506 - recall: 0.7614 - val_accuracy: 0.7385 - val_loss: 0.5135 - val_precision: 0.6008 - val_recall: 0.3109\n",
            "Epoch 20/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7940 - loss: 0.4543 - precision: 0.8499 - recall: 0.7617 - val_accuracy: 0.7374 - val_loss: 0.5151 - val_precision: 0.5893 - val_recall: 0.3321\n",
            "Epoch 21/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.4548 - precision: 0.8484 - recall: 0.7591 - val_accuracy: 0.7374 - val_loss: 0.5129 - val_precision: 0.5833 - val_recall: 0.3526\n",
            "Epoch 22/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7952 - loss: 0.4507 - precision: 0.8449 - recall: 0.7709 - val_accuracy: 0.7341 - val_loss: 0.5153 - val_precision: 0.5682 - val_recall: 0.3724\n",
            "Epoch 23/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7944 - loss: 0.4505 - precision: 0.8443 - recall: 0.7698 - val_accuracy: 0.7357 - val_loss: 0.5156 - val_precision: 0.5712 - val_recall: 0.3804\n",
            "Epoch 24/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7977 - loss: 0.4460 - precision: 0.8443 - recall: 0.7774 - val_accuracy: 0.7349 - val_loss: 0.5167 - val_precision: 0.5619 - val_recall: 0.4174\n",
            "Epoch 25/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.4429 - precision: 0.8436 - recall: 0.7775 - val_accuracy: 0.7349 - val_loss: 0.5177 - val_precision: 0.5618 - val_recall: 0.4178\n",
            "Epoch 26/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7986 - loss: 0.4420 - precision: 0.8416 - recall: 0.7830 - val_accuracy: 0.7315 - val_loss: 0.5176 - val_precision: 0.5486 - val_recall: 0.4526\n",
            "Epoch 27/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8003 - loss: 0.4438 - precision: 0.8419 - recall: 0.7862 - val_accuracy: 0.7313 - val_loss: 0.5203 - val_precision: 0.5487 - val_recall: 0.4493\n",
            "Epoch 28/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7989 - loss: 0.4418 - precision: 0.8382 - recall: 0.7882 - val_accuracy: 0.7258 - val_loss: 0.5189 - val_precision: 0.5354 - val_recall: 0.4599\n",
            "Epoch 29/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8018 - loss: 0.4394 - precision: 0.8367 - recall: 0.7968 - val_accuracy: 0.7300 - val_loss: 0.5161 - val_precision: 0.5424 - val_recall: 0.4800\n",
            "Epoch 30/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8026 - loss: 0.4393 - precision: 0.8367 - recall: 0.7987 - val_accuracy: 0.7269 - val_loss: 0.5227 - val_precision: 0.5331 - val_recall: 0.5189\n",
            "Epoch 31/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8026 - loss: 0.4380 - precision: 0.8395 - recall: 0.7946 - val_accuracy: 0.7236 - val_loss: 0.5230 - val_precision: 0.5273 - val_recall: 0.5163\n",
            "Epoch 32/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8034 - loss: 0.4343 - precision: 0.8371 - recall: 0.7997 - val_accuracy: 0.7321 - val_loss: 0.5188 - val_precision: 0.5420 - val_recall: 0.5313\n",
            "Epoch 33/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8037 - loss: 0.4348 - precision: 0.8365 - recall: 0.8014 - val_accuracy: 0.7306 - val_loss: 0.5187 - val_precision: 0.5450 - val_recall: 0.4676\n",
            "Epoch 34/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8066 - loss: 0.4348 - precision: 0.8355 - recall: 0.8095 - val_accuracy: 0.7304 - val_loss: 0.5233 - val_precision: 0.5437 - val_recall: 0.4760\n",
            "Epoch 35/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8080 - loss: 0.4321 - precision: 0.8375 - recall: 0.8098 - val_accuracy: 0.7307 - val_loss: 0.5323 - val_precision: 0.5419 - val_recall: 0.5020\n",
            "Epoch 36/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8073 - loss: 0.4310 - precision: 0.8356 - recall: 0.8107 - val_accuracy: 0.7308 - val_loss: 0.5262 - val_precision: 0.5413 - val_recall: 0.5115\n",
            "Epoch 37/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8091 - loss: 0.4272 - precision: 0.8390 - recall: 0.8101 - val_accuracy: 0.7355 - val_loss: 0.5271 - val_precision: 0.5537 - val_recall: 0.4852\n",
            "Epoch 38/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8091 - loss: 0.4267 - precision: 0.8371 - recall: 0.8127 - val_accuracy: 0.7293 - val_loss: 0.5307 - val_precision: 0.5345 - val_recall: 0.5639\n",
            "Epoch 39/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8093 - loss: 0.4241 - precision: 0.8354 - recall: 0.8155 - val_accuracy: 0.7280 - val_loss: 0.5331 - val_precision: 0.5361 - val_recall: 0.5082\n",
            "Epoch 40/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8082 - loss: 0.4260 - precision: 0.8382 - recall: 0.8091 - val_accuracy: 0.7291 - val_loss: 0.5279 - val_precision: 0.5375 - val_recall: 0.5174\n",
            "Epoch 41/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8115 - loss: 0.4217 - precision: 0.8415 - recall: 0.8116 - val_accuracy: 0.7337 - val_loss: 0.5297 - val_precision: 0.5452 - val_recall: 0.5295\n",
            "Epoch 42/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8092 - loss: 0.4233 - precision: 0.8379 - recall: 0.8118 - val_accuracy: 0.7375 - val_loss: 0.5295 - val_precision: 0.5559 - val_recall: 0.5024\n",
            "Epoch 43/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8112 - loss: 0.4246 - precision: 0.8423 - recall: 0.8100 - val_accuracy: 0.7347 - val_loss: 0.5255 - val_precision: 0.5546 - val_recall: 0.4628\n",
            "Epoch 44/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8136 - loss: 0.4228 - precision: 0.8418 - recall: 0.8160 - val_accuracy: 0.7344 - val_loss: 0.5251 - val_precision: 0.5508 - val_recall: 0.4907\n",
            "Epoch 45/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8126 - loss: 0.4187 - precision: 0.8425 - recall: 0.8129 - val_accuracy: 0.7368 - val_loss: 0.5246 - val_precision: 0.5599 - val_recall: 0.4606\n",
            "Epoch 46/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8124 - loss: 0.4199 - precision: 0.8436 - recall: 0.8110 - val_accuracy: 0.7348 - val_loss: 0.5294 - val_precision: 0.5496 - val_recall: 0.5071\n",
            "Epoch 47/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.4164 - precision: 0.8482 - recall: 0.8078 - val_accuracy: 0.7354 - val_loss: 0.5298 - val_precision: 0.5532 - val_recall: 0.4870\n",
            "Epoch 48/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8106 - loss: 0.4169 - precision: 0.8419 - recall: 0.8091 - val_accuracy: 0.7338 - val_loss: 0.5366 - val_precision: 0.5464 - val_recall: 0.5192\n",
            "Epoch 49/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.4172 - precision: 0.8428 - recall: 0.8173 - val_accuracy: 0.7383 - val_loss: 0.5323 - val_precision: 0.5569 - val_recall: 0.5068\n",
            "Epoch 50/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8144 - loss: 0.4136 - precision: 0.8432 - recall: 0.8159 - val_accuracy: 0.7370 - val_loss: 0.5320 - val_precision: 0.5531 - val_recall: 0.5167\n",
            "Epoch 51/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.4107 - precision: 0.8452 - recall: 0.8146 - val_accuracy: 0.7365 - val_loss: 0.5407 - val_precision: 0.5534 - val_recall: 0.5046\n",
            "Epoch 52/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.4173 - precision: 0.8463 - recall: 0.8141 - val_accuracy: 0.7313 - val_loss: 0.5310 - val_precision: 0.5437 - val_recall: 0.4969\n",
            "Epoch 53/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8189 - loss: 0.4111 - precision: 0.8437 - recall: 0.8251 - val_accuracy: 0.7350 - val_loss: 0.5276 - val_precision: 0.5534 - val_recall: 0.4782\n",
            "Epoch 54/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8148 - loss: 0.4136 - precision: 0.8359 - recall: 0.8273 - val_accuracy: 0.7339 - val_loss: 0.5332 - val_precision: 0.5449 - val_recall: 0.5372\n",
            "Epoch 55/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8195 - loss: 0.4092 - precision: 0.8433 - recall: 0.8272 - val_accuracy: 0.7329 - val_loss: 0.5315 - val_precision: 0.5448 - val_recall: 0.5192\n",
            "Epoch 56/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8191 - loss: 0.4076 - precision: 0.8448 - recall: 0.8240 - val_accuracy: 0.7307 - val_loss: 0.5422 - val_precision: 0.5381 - val_recall: 0.5485\n",
            "Epoch 57/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.4072 - precision: 0.8449 - recall: 0.8285 - val_accuracy: 0.7272 - val_loss: 0.5433 - val_precision: 0.5316 - val_recall: 0.5511\n",
            "Epoch 58/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.4078 - precision: 0.8407 - recall: 0.8345 - val_accuracy: 0.7329 - val_loss: 0.5354 - val_precision: 0.5471 - val_recall: 0.4951\n",
            "Epoch 59/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8251 - loss: 0.4076 - precision: 0.8444 - recall: 0.8381 - val_accuracy: 0.7304 - val_loss: 0.5415 - val_precision: 0.5369 - val_recall: 0.5562\n",
            "Epoch 60/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8231 - loss: 0.4032 - precision: 0.8426 - recall: 0.8359 - val_accuracy: 0.7312 - val_loss: 0.5455 - val_precision: 0.5398 - val_recall: 0.5390\n",
            "Epoch 61/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8222 - loss: 0.4040 - precision: 0.8410 - recall: 0.8364 - val_accuracy: 0.7288 - val_loss: 0.5376 - val_precision: 0.5370 - val_recall: 0.5159\n",
            "Epoch 62/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8243 - loss: 0.4050 - precision: 0.8424 - recall: 0.8389 - val_accuracy: 0.7300 - val_loss: 0.5356 - val_precision: 0.5426 - val_recall: 0.4782\n",
            "Epoch 63/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.4035 - precision: 0.8467 - recall: 0.8366 - val_accuracy: 0.7232 - val_loss: 0.5367 - val_precision: 0.5247 - val_recall: 0.5529\n",
            "Epoch 64/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8259 - loss: 0.4019 - precision: 0.8423 - recall: 0.8428 - val_accuracy: 0.7288 - val_loss: 0.5332 - val_precision: 0.5397 - val_recall: 0.4830\n",
            "Epoch 65/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8252 - loss: 0.4036 - precision: 0.8434 - recall: 0.8396 - val_accuracy: 0.7274 - val_loss: 0.5345 - val_precision: 0.5357 - val_recall: 0.4973\n",
            "Epoch 66/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.3976 - precision: 0.8518 - recall: 0.8331 - val_accuracy: 0.7337 - val_loss: 0.5347 - val_precision: 0.5478 - val_recall: 0.5031\n",
            "Epoch 67/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8274 - loss: 0.4020 - precision: 0.8502 - recall: 0.8347 - val_accuracy: 0.7347 - val_loss: 0.5299 - val_precision: 0.5572 - val_recall: 0.4438\n",
            "Epoch 68/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8276 - loss: 0.3975 - precision: 0.8496 - recall: 0.8361 - val_accuracy: 0.7362 - val_loss: 0.5349 - val_precision: 0.5590 - val_recall: 0.4559\n",
            "Epoch 69/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8315 - loss: 0.3985 - precision: 0.8486 - recall: 0.8462 - val_accuracy: 0.7179 - val_loss: 0.5590 - val_precision: 0.5151 - val_recall: 0.5741\n",
            "Epoch 70/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8276 - loss: 0.3960 - precision: 0.8486 - recall: 0.8376 - val_accuracy: 0.7320 - val_loss: 0.5424 - val_precision: 0.5437 - val_recall: 0.5104\n",
            "Epoch 71/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8295 - loss: 0.3968 - precision: 0.8500 - recall: 0.8396 - val_accuracy: 0.7239 - val_loss: 0.5387 - val_precision: 0.5262 - val_recall: 0.5441\n",
            "Epoch 72/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8318 - loss: 0.3936 - precision: 0.8477 - recall: 0.8481 - val_accuracy: 0.7302 - val_loss: 0.5443 - val_precision: 0.5412 - val_recall: 0.4976\n",
            "Epoch 73/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8307 - loss: 0.3908 - precision: 0.8567 - recall: 0.8330 - val_accuracy: 0.7280 - val_loss: 0.5482 - val_precision: 0.5384 - val_recall: 0.4804\n",
            "Epoch 74/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3954 - precision: 0.8525 - recall: 0.8339 - val_accuracy: 0.7291 - val_loss: 0.5414 - val_precision: 0.5406 - val_recall: 0.4804\n",
            "Epoch 75/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 0.3900 - precision: 0.8567 - recall: 0.8330 - val_accuracy: 0.7241 - val_loss: 0.5601 - val_precision: 0.5275 - val_recall: 0.5276\n",
            "Epoch 76/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.3926 - precision: 0.8555 - recall: 0.8351 - val_accuracy: 0.7382 - val_loss: 0.5388 - val_precision: 0.5622 - val_recall: 0.4665\n",
            "Epoch 77/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8311 - loss: 0.3917 - precision: 0.8531 - recall: 0.8387 - val_accuracy: 0.7327 - val_loss: 0.5452 - val_precision: 0.5470 - val_recall: 0.4918\n",
            "Epoch 78/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8340 - loss: 0.3855 - precision: 0.8584 - recall: 0.8378 - val_accuracy: 0.7373 - val_loss: 0.5434 - val_precision: 0.5663 - val_recall: 0.4284\n",
            "Epoch 79/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.3919 - precision: 0.8564 - recall: 0.8381 - val_accuracy: 0.7373 - val_loss: 0.5362 - val_precision: 0.5662 - val_recall: 0.4288\n",
            "Epoch 80/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8336 - loss: 0.3905 - precision: 0.8611 - recall: 0.8332 - val_accuracy: 0.7381 - val_loss: 0.5393 - val_precision: 0.5670 - val_recall: 0.4354\n",
            "Epoch 81/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.3832 - precision: 0.8649 - recall: 0.8270 - val_accuracy: 0.7359 - val_loss: 0.5466 - val_precision: 0.5653 - val_recall: 0.4134\n",
            "Epoch 82/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8374 - loss: 0.3849 - precision: 0.8655 - recall: 0.8356 - val_accuracy: 0.7371 - val_loss: 0.5406 - val_precision: 0.5699 - val_recall: 0.4061\n",
            "Epoch 83/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8368 - loss: 0.3842 - precision: 0.8645 - recall: 0.8357 - val_accuracy: 0.7390 - val_loss: 0.5449 - val_precision: 0.5735 - val_recall: 0.4145\n",
            "Epoch 84/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8369 - loss: 0.3830 - precision: 0.8695 - recall: 0.8292 - val_accuracy: 0.7279 - val_loss: 0.5584 - val_precision: 0.5383 - val_recall: 0.4789\n",
            "Epoch 85/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.3812 - precision: 0.8663 - recall: 0.8324 - val_accuracy: 0.7388 - val_loss: 0.5314 - val_precision: 0.5797 - val_recall: 0.3834\n",
            "Epoch 86/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 0.3810 - precision: 0.8659 - recall: 0.8369 - val_accuracy: 0.7391 - val_loss: 0.5351 - val_precision: 0.5777 - val_recall: 0.3962\n",
            "Epoch 87/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8378 - loss: 0.3780 - precision: 0.8690 - recall: 0.8318 - val_accuracy: 0.7368 - val_loss: 0.5302 - val_precision: 0.5810 - val_recall: 0.3534\n",
            "Epoch 88/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8377 - loss: 0.3777 - precision: 0.8680 - recall: 0.8330 - val_accuracy: 0.7379 - val_loss: 0.5358 - val_precision: 0.5714 - val_recall: 0.4086\n",
            "Epoch 89/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 0.3792 - precision: 0.8685 - recall: 0.8372 - val_accuracy: 0.7380 - val_loss: 0.5314 - val_precision: 0.5752 - val_recall: 0.3922\n",
            "Epoch 90/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8352 - loss: 0.3784 - precision: 0.8695 - recall: 0.8256 - val_accuracy: 0.7381 - val_loss: 0.5286 - val_precision: 0.5760 - val_recall: 0.3900\n",
            "Epoch 91/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8396 - loss: 0.3771 - precision: 0.8734 - recall: 0.8301 - val_accuracy: 0.7365 - val_loss: 0.5362 - val_precision: 0.5703 - val_recall: 0.3951\n",
            "Epoch 92/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8385 - loss: 0.3755 - precision: 0.8752 - recall: 0.8255 - val_accuracy: 0.7326 - val_loss: 0.5429 - val_precision: 0.5589 - val_recall: 0.3995\n",
            "Epoch 93/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8390 - loss: 0.3741 - precision: 0.8721 - recall: 0.8303 - val_accuracy: 0.7344 - val_loss: 0.5424 - val_precision: 0.5578 - val_recall: 0.4365\n",
            "Epoch 94/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8405 - loss: 0.3761 - precision: 0.8719 - recall: 0.8337 - val_accuracy: 0.7369 - val_loss: 0.5336 - val_precision: 0.5710 - val_recall: 0.3977\n",
            "Epoch 95/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.3754 - precision: 0.8694 - recall: 0.8361 - val_accuracy: 0.7337 - val_loss: 0.5397 - val_precision: 0.5687 - val_recall: 0.3636\n",
            "Epoch 96/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.3743 - precision: 0.8726 - recall: 0.8303 - val_accuracy: 0.7370 - val_loss: 0.5340 - val_precision: 0.5752 - val_recall: 0.3797\n",
            "Epoch 97/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8420 - loss: 0.3737 - precision: 0.8719 - recall: 0.8370 - val_accuracy: 0.7371 - val_loss: 0.5418 - val_precision: 0.5744 - val_recall: 0.3845\n",
            "Epoch 98/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.3705 - precision: 0.8748 - recall: 0.8349 - val_accuracy: 0.7362 - val_loss: 0.5379 - val_precision: 0.5704 - val_recall: 0.3903\n",
            "Epoch 99/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8413 - loss: 0.3675 - precision: 0.8749 - recall: 0.8318 - val_accuracy: 0.7354 - val_loss: 0.5382 - val_precision: 0.5600 - val_recall: 0.4376\n",
            "Epoch 100/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8355 - loss: 0.3800 - precision: 0.8679 - recall: 0.8284 - val_accuracy: 0.7365 - val_loss: 0.5351 - val_precision: 0.5701 - val_recall: 0.3958\n",
            "Epoch 101/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8412 - loss: 0.3731 - precision: 0.8727 - recall: 0.8344 - val_accuracy: 0.7357 - val_loss: 0.5390 - val_precision: 0.5588 - val_recall: 0.4504\n",
            "Epoch 102/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8383 - loss: 0.3755 - precision: 0.8709 - recall: 0.8303 - val_accuracy: 0.7380 - val_loss: 0.5384 - val_precision: 0.5667 - val_recall: 0.4354\n",
            "Epoch 103/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8383 - loss: 0.3729 - precision: 0.8708 - recall: 0.8305 - val_accuracy: 0.7335 - val_loss: 0.5481 - val_precision: 0.5597 - val_recall: 0.4086\n",
            "Epoch 104/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3758 - precision: 0.8700 - recall: 0.8342 - val_accuracy: 0.7339 - val_loss: 0.5283 - val_precision: 0.5681 - val_recall: 0.3695\n",
            "Epoch 105/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8361 - loss: 0.3737 - precision: 0.8707 - recall: 0.8261 - val_accuracy: 0.7334 - val_loss: 0.5426 - val_precision: 0.5585 - val_recall: 0.4141\n",
            "Epoch 106/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.3697 - precision: 0.8757 - recall: 0.8303 - val_accuracy: 0.7360 - val_loss: 0.5337 - val_precision: 0.5779 - val_recall: 0.3559\n",
            "Epoch 107/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8403 - loss: 0.3692 - precision: 0.8722 - recall: 0.8331 - val_accuracy: 0.7341 - val_loss: 0.5415 - val_precision: 0.5635 - val_recall: 0.3966\n",
            "Epoch 108/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8427 - loss: 0.3641 - precision: 0.8769 - recall: 0.8321 - val_accuracy: 0.7341 - val_loss: 0.5285 - val_precision: 0.5744 - val_recall: 0.3449\n",
            "Epoch 109/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3678 - precision: 0.8735 - recall: 0.8295 - val_accuracy: 0.7360 - val_loss: 0.5328 - val_precision: 0.5759 - val_recall: 0.3640\n",
            "Epoch 110/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8418 - loss: 0.3704 - precision: 0.8741 - recall: 0.8338 - val_accuracy: 0.7372 - val_loss: 0.5324 - val_precision: 0.5847 - val_recall: 0.3449\n",
            "Epoch 111/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8429 - loss: 0.3674 - precision: 0.8771 - recall: 0.8324 - val_accuracy: 0.7367 - val_loss: 0.5436 - val_precision: 0.5659 - val_recall: 0.4215\n",
            "Epoch 112/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.3719 - precision: 0.8769 - recall: 0.8307 - val_accuracy: 0.7321 - val_loss: 0.5527 - val_precision: 0.5544 - val_recall: 0.4200\n",
            "Epoch 113/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.3706 - precision: 0.8748 - recall: 0.8294 - val_accuracy: 0.7342 - val_loss: 0.5398 - val_precision: 0.5677 - val_recall: 0.3761\n",
            "Epoch 114/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.3663 - precision: 0.8722 - recall: 0.8359 - val_accuracy: 0.7358 - val_loss: 0.5469 - val_precision: 0.5652 - val_recall: 0.4127\n",
            "Epoch 115/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.3652 - precision: 0.8773 - recall: 0.8350 - val_accuracy: 0.7331 - val_loss: 0.5410 - val_precision: 0.5647 - val_recall: 0.3739\n",
            "Epoch 116/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8432 - loss: 0.3619 - precision: 0.8765 - recall: 0.8335 - val_accuracy: 0.7333 - val_loss: 0.5394 - val_precision: 0.5622 - val_recall: 0.3907\n",
            "Epoch 117/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8439 - loss: 0.3606 - precision: 0.8741 - recall: 0.8383 - val_accuracy: 0.7338 - val_loss: 0.5399 - val_precision: 0.5663 - val_recall: 0.3768\n",
            "Epoch 118/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8459 - loss: 0.3622 - precision: 0.8784 - recall: 0.8370 - val_accuracy: 0.7342 - val_loss: 0.5593 - val_precision: 0.5538 - val_recall: 0.4621\n",
            "Epoch 119/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8429 - loss: 0.3595 - precision: 0.8752 - recall: 0.8347 - val_accuracy: 0.7365 - val_loss: 0.5354 - val_precision: 0.5691 - val_recall: 0.4010\n",
            "Epoch 120/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8444 - loss: 0.3627 - precision: 0.8766 - recall: 0.8360 - val_accuracy: 0.7354 - val_loss: 0.5454 - val_precision: 0.5741 - val_recall: 0.3632\n",
            "Epoch 121/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8450 - loss: 0.3592 - precision: 0.8766 - recall: 0.8373 - val_accuracy: 0.7356 - val_loss: 0.5368 - val_precision: 0.5739 - val_recall: 0.3669\n",
            "Epoch 122/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8485 - loss: 0.3613 - precision: 0.8767 - recall: 0.8446 - val_accuracy: 0.7367 - val_loss: 0.5519 - val_precision: 0.5659 - val_recall: 0.4211\n",
            "Epoch 123/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8451 - loss: 0.3621 - precision: 0.8798 - recall: 0.8336 - val_accuracy: 0.7332 - val_loss: 0.5386 - val_precision: 0.5561 - val_recall: 0.4262\n",
            "Epoch 124/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8426 - loss: 0.3633 - precision: 0.8727 - recall: 0.8372 - val_accuracy: 0.7337 - val_loss: 0.5428 - val_precision: 0.5612 - val_recall: 0.4028\n",
            "Epoch 125/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.3567 - precision: 0.8785 - recall: 0.8380 - val_accuracy: 0.7362 - val_loss: 0.5385 - val_precision: 0.5680 - val_recall: 0.4021\n",
            "Epoch 126/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8444 - loss: 0.3607 - precision: 0.8761 - recall: 0.8367 - val_accuracy: 0.7329 - val_loss: 0.5377 - val_precision: 0.5625 - val_recall: 0.3837\n",
            "Epoch 127/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8455 - loss: 0.3578 - precision: 0.8756 - recall: 0.8398 - val_accuracy: 0.7358 - val_loss: 0.5431 - val_precision: 0.5605 - val_recall: 0.4412\n",
            "Epoch 128/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8470 - loss: 0.3589 - precision: 0.8746 - recall: 0.8442 - val_accuracy: 0.7327 - val_loss: 0.5488 - val_precision: 0.5567 - val_recall: 0.4152\n",
            "Epoch 129/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.3575 - precision: 0.8738 - recall: 0.8419 - val_accuracy: 0.7339 - val_loss: 0.5321 - val_precision: 0.5671 - val_recall: 0.3742\n",
            "Epoch 130/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8465 - loss: 0.3620 - precision: 0.8755 - recall: 0.8421 - val_accuracy: 0.7273 - val_loss: 0.5470 - val_precision: 0.5509 - val_recall: 0.3566\n",
            "Epoch 131/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8470 - loss: 0.3554 - precision: 0.8787 - recall: 0.8389 - val_accuracy: 0.7292 - val_loss: 0.5476 - val_precision: 0.5514 - val_recall: 0.3889\n",
            "Epoch 132/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8466 - loss: 0.3558 - precision: 0.8803 - recall: 0.8362 - val_accuracy: 0.7305 - val_loss: 0.5498 - val_precision: 0.5498 - val_recall: 0.4244\n",
            "Epoch 133/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8512 - loss: 0.3553 - precision: 0.8772 - recall: 0.8497 - val_accuracy: 0.7320 - val_loss: 0.5586 - val_precision: 0.5575 - val_recall: 0.3977\n",
            "Epoch 134/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8466 - loss: 0.3558 - precision: 0.8745 - recall: 0.8436 - val_accuracy: 0.7342 - val_loss: 0.5500 - val_precision: 0.5606 - val_recall: 0.4149\n",
            "Epoch 135/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8488 - loss: 0.3548 - precision: 0.8784 - recall: 0.8431 - val_accuracy: 0.7367 - val_loss: 0.5413 - val_precision: 0.5806 - val_recall: 0.3534\n",
            "Epoch 136/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8485 - loss: 0.3512 - precision: 0.8820 - recall: 0.8380 - val_accuracy: 0.7399 - val_loss: 0.5410 - val_precision: 0.5870 - val_recall: 0.3680\n",
            "Epoch 137/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8500 - loss: 0.3536 - precision: 0.8820 - recall: 0.8411 - val_accuracy: 0.7325 - val_loss: 0.5434 - val_precision: 0.5548 - val_recall: 0.4244\n",
            "Epoch 138/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.3558 - precision: 0.8750 - recall: 0.8480 - val_accuracy: 0.7360 - val_loss: 0.5507 - val_precision: 0.5660 - val_recall: 0.4112\n",
            "Epoch 139/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8487 - loss: 0.3557 - precision: 0.8796 - recall: 0.8413 - val_accuracy: 0.7359 - val_loss: 0.5359 - val_precision: 0.5823 - val_recall: 0.3380\n",
            "Epoch 140/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8498 - loss: 0.3549 - precision: 0.8803 - recall: 0.8428 - val_accuracy: 0.7317 - val_loss: 0.5522 - val_precision: 0.5560 - val_recall: 0.4017\n",
            "Epoch 141/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8502 - loss: 0.3508 - precision: 0.8771 - recall: 0.8476 - val_accuracy: 0.7362 - val_loss: 0.5434 - val_precision: 0.5649 - val_recall: 0.4193\n",
            "Epoch 142/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8482 - loss: 0.3528 - precision: 0.8782 - recall: 0.8421 - val_accuracy: 0.7336 - val_loss: 0.5435 - val_precision: 0.5629 - val_recall: 0.3918\n",
            "Epoch 143/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.3559 - precision: 0.8784 - recall: 0.8372 - val_accuracy: 0.7368 - val_loss: 0.5545 - val_precision: 0.5705 - val_recall: 0.3984\n",
            "Epoch 144/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8523 - loss: 0.3512 - precision: 0.8815 - recall: 0.8464 - val_accuracy: 0.7332 - val_loss: 0.5483 - val_precision: 0.5599 - val_recall: 0.4021\n",
            "Epoch 145/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8506 - loss: 0.3502 - precision: 0.8790 - recall: 0.8461 - val_accuracy: 0.7320 - val_loss: 0.5411 - val_precision: 0.5588 - val_recall: 0.3896\n",
            "Epoch 146/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8464 - loss: 0.3592 - precision: 0.8714 - recall: 0.8470 - val_accuracy: 0.7348 - val_loss: 0.5508 - val_precision: 0.5557 - val_recall: 0.4566\n",
            "Epoch 147/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.3512 - precision: 0.8770 - recall: 0.8455 - val_accuracy: 0.7301 - val_loss: 0.5588 - val_precision: 0.5572 - val_recall: 0.3676\n",
            "Epoch 148/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8512 - loss: 0.3487 - precision: 0.8794 - recall: 0.8468 - val_accuracy: 0.7331 - val_loss: 0.5497 - val_precision: 0.5615 - val_recall: 0.3911\n",
            "Epoch 149/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.3517 - precision: 0.8769 - recall: 0.8456 - val_accuracy: 0.7303 - val_loss: 0.5534 - val_precision: 0.5503 - val_recall: 0.4163\n",
            "Epoch 150/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8515 - loss: 0.3447 - precision: 0.8809 - recall: 0.8457 - val_accuracy: 0.7242 - val_loss: 0.5492 - val_precision: 0.5369 - val_recall: 0.4024\n",
            "Epoch 151/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8523 - loss: 0.3477 - precision: 0.8797 - recall: 0.8489 - val_accuracy: 0.7294 - val_loss: 0.5469 - val_precision: 0.5462 - val_recall: 0.4328\n",
            "Epoch 152/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8551 - loss: 0.3458 - precision: 0.8799 - recall: 0.8544 - val_accuracy: 0.7195 - val_loss: 0.5591 - val_precision: 0.5226 - val_recall: 0.4522\n",
            "Epoch 153/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8503 - loss: 0.3494 - precision: 0.8769 - recall: 0.8482 - val_accuracy: 0.7260 - val_loss: 0.5523 - val_precision: 0.5441 - val_recall: 0.3797\n",
            "Epoch 154/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8492 - loss: 0.3488 - precision: 0.8786 - recall: 0.8437 - val_accuracy: 0.7349 - val_loss: 0.5481 - val_precision: 0.5602 - val_recall: 0.4273\n",
            "Epoch 155/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8546 - loss: 0.3403 - precision: 0.8807 - recall: 0.8525 - val_accuracy: 0.7367 - val_loss: 0.5484 - val_precision: 0.5820 - val_recall: 0.3482\n",
            "Epoch 156/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8506 - loss: 0.3468 - precision: 0.8809 - recall: 0.8437 - val_accuracy: 0.7358 - val_loss: 0.5512 - val_precision: 0.5704 - val_recall: 0.3856\n",
            "Epoch 157/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8555 - loss: 0.3431 - precision: 0.8798 - recall: 0.8554 - val_accuracy: 0.7316 - val_loss: 0.5598 - val_precision: 0.5484 - val_recall: 0.4562\n",
            "Epoch 158/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8501 - loss: 0.3501 - precision: 0.8766 - recall: 0.8482 - val_accuracy: 0.7326 - val_loss: 0.5456 - val_precision: 0.5566 - val_recall: 0.4141\n",
            "Epoch 159/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8514 - loss: 0.3442 - precision: 0.8782 - recall: 0.8489 - val_accuracy: 0.7349 - val_loss: 0.5457 - val_precision: 0.5631 - val_recall: 0.4101\n",
            "Epoch 160/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8522 - loss: 0.3474 - precision: 0.8813 - recall: 0.8465 - val_accuracy: 0.7316 - val_loss: 0.5539 - val_precision: 0.5548 - val_recall: 0.4079\n",
            "Epoch 161/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.3416 - precision: 0.8823 - recall: 0.8512 - val_accuracy: 0.7321 - val_loss: 0.5616 - val_precision: 0.5754 - val_recall: 0.3145\n",
            "Epoch 162/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8536 - loss: 0.3381 - precision: 0.8824 - recall: 0.8480 - val_accuracy: 0.7287 - val_loss: 0.5456 - val_precision: 0.5448 - val_recall: 0.4299\n",
            "Epoch 163/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8551 - loss: 0.3417 - precision: 0.8794 - recall: 0.8550 - val_accuracy: 0.7300 - val_loss: 0.5580 - val_precision: 0.5531 - val_recall: 0.3911\n",
            "Epoch 164/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8563 - loss: 0.3413 - precision: 0.8848 - recall: 0.8508 - val_accuracy: 0.7180 - val_loss: 0.5572 - val_precision: 0.5205 - val_recall: 0.4317\n",
            "Epoch 165/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8516 - loss: 0.3458 - precision: 0.8753 - recall: 0.8531 - val_accuracy: 0.7197 - val_loss: 0.5536 - val_precision: 0.5238 - val_recall: 0.4398\n",
            "Epoch 166/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8502 - loss: 0.3492 - precision: 0.8767 - recall: 0.8481 - val_accuracy: 0.7172 - val_loss: 0.5551 - val_precision: 0.5186 - val_recall: 0.4394\n",
            "Epoch 167/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8542 - loss: 0.3461 - precision: 0.8769 - recall: 0.8564 - val_accuracy: 0.7318 - val_loss: 0.5503 - val_precision: 0.5530 - val_recall: 0.4240\n",
            "Epoch 168/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8512 - loss: 0.3487 - precision: 0.8761 - recall: 0.8509 - val_accuracy: 0.7277 - val_loss: 0.5477 - val_precision: 0.5482 - val_recall: 0.3830\n",
            "Epoch 169/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.3446 - precision: 0.8772 - recall: 0.8542 - val_accuracy: 0.7359 - val_loss: 0.5332 - val_precision: 0.5757 - val_recall: 0.3636\n",
            "Epoch 170/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8554 - loss: 0.3429 - precision: 0.8801 - recall: 0.8547 - val_accuracy: 0.7320 - val_loss: 0.5349 - val_precision: 0.5525 - val_recall: 0.4313\n",
            "Epoch 171/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8506 - loss: 0.3468 - precision: 0.8725 - recall: 0.8547 - val_accuracy: 0.7267 - val_loss: 0.5522 - val_precision: 0.5403 - val_recall: 0.4291\n",
            "Epoch 172/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.3438 - precision: 0.8802 - recall: 0.8553 - val_accuracy: 0.7297 - val_loss: 0.5422 - val_precision: 0.5503 - val_recall: 0.4068\n",
            "Epoch 173/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.3439 - precision: 0.8781 - recall: 0.8531 - val_accuracy: 0.7208 - val_loss: 0.5544 - val_precision: 0.5310 - val_recall: 0.3731\n",
            "Epoch 174/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.3426 - precision: 0.8785 - recall: 0.8589 - val_accuracy: 0.7324 - val_loss: 0.5474 - val_precision: 0.5684 - val_recall: 0.3468\n",
            "Epoch 175/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.3422 - precision: 0.8810 - recall: 0.8528 - val_accuracy: 0.7231 - val_loss: 0.5626 - val_precision: 0.5319 - val_recall: 0.4302\n",
            "Epoch 176/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8536 - loss: 0.3456 - precision: 0.8768 - recall: 0.8552 - val_accuracy: 0.7269 - val_loss: 0.5522 - val_precision: 0.5433 - val_recall: 0.4042\n",
            "Epoch 177/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8534 - loss: 0.3437 - precision: 0.8766 - recall: 0.8550 - val_accuracy: 0.7249 - val_loss: 0.5564 - val_precision: 0.5393 - val_recall: 0.3969\n",
            "Epoch 178/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8568 - loss: 0.3386 - precision: 0.8798 - recall: 0.8580 - val_accuracy: 0.7275 - val_loss: 0.5447 - val_precision: 0.5430 - val_recall: 0.4204\n",
            "Epoch 179/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8540 - loss: 0.3473 - precision: 0.8758 - recall: 0.8574 - val_accuracy: 0.7121 - val_loss: 0.5673 - val_precision: 0.5077 - val_recall: 0.4588\n",
            "Epoch 180/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8556 - loss: 0.3447 - precision: 0.8775 - recall: 0.8585 - val_accuracy: 0.7303 - val_loss: 0.5429 - val_precision: 0.5627 - val_recall: 0.3420\n",
            "Epoch 181/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.3434 - precision: 0.8774 - recall: 0.8588 - val_accuracy: 0.7222 - val_loss: 0.5513 - val_precision: 0.5303 - val_recall: 0.4233\n",
            "Epoch 182/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8516 - loss: 0.3450 - precision: 0.8758 - recall: 0.8525 - val_accuracy: 0.7309 - val_loss: 0.5606 - val_precision: 0.5521 - val_recall: 0.4149\n",
            "Epoch 183/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8563 - loss: 0.3421 - precision: 0.8825 - recall: 0.8535 - val_accuracy: 0.7293 - val_loss: 0.5530 - val_precision: 0.5492 - val_recall: 0.4068\n",
            "Epoch 184/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8558 - loss: 0.3409 - precision: 0.8779 - recall: 0.8585 - val_accuracy: 0.7331 - val_loss: 0.5500 - val_precision: 0.5682 - val_recall: 0.3570\n",
            "Epoch 185/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.3438 - precision: 0.8802 - recall: 0.8580 - val_accuracy: 0.7087 - val_loss: 0.5652 - val_precision: 0.5012 - val_recall: 0.4617\n",
            "Epoch 186/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8535 - loss: 0.3470 - precision: 0.8742 - recall: 0.8584 - val_accuracy: 0.7317 - val_loss: 0.5509 - val_precision: 0.5703 - val_recall: 0.3281\n",
            "Epoch 187/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8559 - loss: 0.3422 - precision: 0.8824 - recall: 0.8529 - val_accuracy: 0.7250 - val_loss: 0.5537 - val_precision: 0.5451 - val_recall: 0.3519\n",
            "Epoch 188/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8551 - loss: 0.3401 - precision: 0.8804 - recall: 0.8538 - val_accuracy: 0.7338 - val_loss: 0.5313 - val_precision: 0.5720 - val_recall: 0.3504\n",
            "Epoch 189/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8517 - loss: 0.3439 - precision: 0.8755 - recall: 0.8529 - val_accuracy: 0.7303 - val_loss: 0.5424 - val_precision: 0.5536 - val_recall: 0.3933\n",
            "Epoch 190/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8571 - loss: 0.3396 - precision: 0.8792 - recall: 0.8594 - val_accuracy: 0.7340 - val_loss: 0.5478 - val_precision: 0.5893 - val_recall: 0.2937\n",
            "Epoch 191/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.3454 - precision: 0.8814 - recall: 0.8506 - val_accuracy: 0.7296 - val_loss: 0.5648 - val_precision: 0.5617 - val_recall: 0.3369\n",
            "Epoch 192/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8592 - loss: 0.3383 - precision: 0.8815 - recall: 0.8609 - val_accuracy: 0.7214 - val_loss: 0.5521 - val_precision: 0.5325 - val_recall: 0.3746\n",
            "Epoch 193/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8545 - loss: 0.3428 - precision: 0.8751 - recall: 0.8593 - val_accuracy: 0.7251 - val_loss: 0.5517 - val_precision: 0.5454 - val_recall: 0.3519\n",
            "Epoch 194/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8585 - loss: 0.3358 - precision: 0.8806 - recall: 0.8608 - val_accuracy: 0.7216 - val_loss: 0.5573 - val_precision: 0.5345 - val_recall: 0.3607\n",
            "Epoch 195/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8520 - loss: 0.3445 - precision: 0.8773 - recall: 0.8512 - val_accuracy: 0.7150 - val_loss: 0.5545 - val_precision: 0.5132 - val_recall: 0.4639\n",
            "Epoch 196/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8553 - loss: 0.3439 - precision: 0.8762 - recall: 0.8596 - val_accuracy: 0.7266 - val_loss: 0.5552 - val_precision: 0.5520 - val_recall: 0.3380\n",
            "Epoch 197/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8595 - loss: 0.3420 - precision: 0.8801 - recall: 0.8635 - val_accuracy: 0.7152 - val_loss: 0.5575 - val_precision: 0.5129 - val_recall: 0.4863\n",
            "Epoch 198/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8597 - loss: 0.3393 - precision: 0.8800 - recall: 0.8639 - val_accuracy: 0.7114 - val_loss: 0.5589 - val_precision: 0.5068 - val_recall: 0.4244\n",
            "Epoch 199/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8584 - loss: 0.3402 - precision: 0.8835 - recall: 0.8568 - val_accuracy: 0.7177 - val_loss: 0.5627 - val_precision: 0.5213 - val_recall: 0.4039\n",
            "Epoch 200/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8636 - loss: 0.3318 - precision: 0.8856 - recall: 0.8650 - val_accuracy: 0.7263 - val_loss: 0.5522 - val_precision: 0.5444 - val_recall: 0.3841\n",
            "Epoch 201/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8606 - loss: 0.3356 - precision: 0.8847 - recall: 0.8599 - val_accuracy: 0.7273 - val_loss: 0.5514 - val_precision: 0.5452 - val_recall: 0.3977\n",
            "Epoch 202/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8603 - loss: 0.3368 - precision: 0.8856 - recall: 0.8580 - val_accuracy: 0.7263 - val_loss: 0.5514 - val_precision: 0.5475 - val_recall: 0.3607\n",
            "Epoch 203/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8568 - loss: 0.3375 - precision: 0.8812 - recall: 0.8562 - val_accuracy: 0.7179 - val_loss: 0.5600 - val_precision: 0.5238 - val_recall: 0.3702\n",
            "Epoch 204/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8584 - loss: 0.3401 - precision: 0.8801 - recall: 0.8610 - val_accuracy: 0.7162 - val_loss: 0.5582 - val_precision: 0.5172 - val_recall: 0.4185\n",
            "Epoch 205/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8576 - loss: 0.3359 - precision: 0.8784 - recall: 0.8616 - val_accuracy: 0.7107 - val_loss: 0.5713 - val_precision: 0.5056 - val_recall: 0.4138\n",
            "Epoch 206/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8584 - loss: 0.3333 - precision: 0.8841 - recall: 0.8559 - val_accuracy: 0.7133 - val_loss: 0.5732 - val_precision: 0.5115 - val_recall: 0.3991\n",
            "Epoch 207/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8575 - loss: 0.3362 - precision: 0.8819 - recall: 0.8569 - val_accuracy: 0.7280 - val_loss: 0.5516 - val_precision: 0.5552 - val_recall: 0.3442\n",
            "Epoch 208/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8576 - loss: 0.3347 - precision: 0.8821 - recall: 0.8568 - val_accuracy: 0.7156 - val_loss: 0.5625 - val_precision: 0.5166 - val_recall: 0.4046\n",
            "Epoch 209/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8609 - loss: 0.3321 - precision: 0.8834 - recall: 0.8619 - val_accuracy: 0.7256 - val_loss: 0.5626 - val_precision: 0.5419 - val_recall: 0.3881\n",
            "Epoch 210/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8595 - loss: 0.3336 - precision: 0.8814 - recall: 0.8616 - val_accuracy: 0.7292 - val_loss: 0.5531 - val_precision: 0.5652 - val_recall: 0.3142\n",
            "Epoch 211/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8559 - loss: 0.3384 - precision: 0.8794 - recall: 0.8567 - val_accuracy: 0.7248 - val_loss: 0.5501 - val_precision: 0.5420 - val_recall: 0.3709\n",
            "Epoch 212/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8604 - loss: 0.3319 - precision: 0.8828 - recall: 0.8619 - val_accuracy: 0.7188 - val_loss: 0.5631 - val_precision: 0.5253 - val_recall: 0.3841\n",
            "Epoch 213/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8648 - loss: 0.3311 - precision: 0.8859 - recall: 0.8670 - val_accuracy: 0.7122 - val_loss: 0.5668 - val_precision: 0.5092 - val_recall: 0.3958\n",
            "Epoch 214/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8623 - loss: 0.3305 - precision: 0.8859 - recall: 0.8618 - val_accuracy: 0.7193 - val_loss: 0.5621 - val_precision: 0.5237 - val_recall: 0.4255\n",
            "Epoch 215/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8615 - loss: 0.3348 - precision: 0.8827 - recall: 0.8641 - val_accuracy: 0.7205 - val_loss: 0.5494 - val_precision: 0.5281 - val_recall: 0.4031\n",
            "Epoch 216/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.3270 - precision: 0.8861 - recall: 0.8624 - val_accuracy: 0.7189 - val_loss: 0.5605 - val_precision: 0.5231 - val_recall: 0.4222\n",
            "Epoch 217/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8604 - loss: 0.3296 - precision: 0.8819 - recall: 0.8630 - val_accuracy: 0.7296 - val_loss: 0.5484 - val_precision: 0.5596 - val_recall: 0.3471\n",
            "Epoch 218/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8625 - loss: 0.3299 - precision: 0.8847 - recall: 0.8637 - val_accuracy: 0.7284 - val_loss: 0.5632 - val_precision: 0.5600 - val_recall: 0.3248\n",
            "Epoch 219/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8602 - loss: 0.3297 - precision: 0.8857 - recall: 0.8576 - val_accuracy: 0.7226 - val_loss: 0.5541 - val_precision: 0.5380 - val_recall: 0.3523\n",
            "Epoch 220/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8633 - loss: 0.3284 - precision: 0.8840 - recall: 0.8663 - val_accuracy: 0.7236 - val_loss: 0.5492 - val_precision: 0.5430 - val_recall: 0.3372\n",
            "Epoch 221/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8621 - loss: 0.3320 - precision: 0.8873 - recall: 0.8597 - val_accuracy: 0.7256 - val_loss: 0.5610 - val_precision: 0.5453 - val_recall: 0.3614\n",
            "Epoch 222/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3305 - precision: 0.8892 - recall: 0.8578 - val_accuracy: 0.7258 - val_loss: 0.5542 - val_precision: 0.5446 - val_recall: 0.3709\n",
            "Epoch 223/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8616 - loss: 0.3319 - precision: 0.8839 - recall: 0.8629 - val_accuracy: 0.7246 - val_loss: 0.5638 - val_precision: 0.5484 - val_recall: 0.3215\n",
            "Epoch 224/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.3326 - precision: 0.8874 - recall: 0.8559 - val_accuracy: 0.7216 - val_loss: 0.5552 - val_precision: 0.5274 - val_recall: 0.4475\n",
            "Epoch 225/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.3338 - precision: 0.8824 - recall: 0.8600 - val_accuracy: 0.7275 - val_loss: 0.5474 - val_precision: 0.5486 - val_recall: 0.3761\n",
            "Epoch 226/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8616 - loss: 0.3302 - precision: 0.8875 - recall: 0.8583 - val_accuracy: 0.7245 - val_loss: 0.5596 - val_precision: 0.5404 - val_recall: 0.3775\n",
            "Epoch 227/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.3340 - precision: 0.8858 - recall: 0.8636 - val_accuracy: 0.7240 - val_loss: 0.5462 - val_precision: 0.5382 - val_recall: 0.3845\n",
            "Epoch 228/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8595 - loss: 0.3315 - precision: 0.8825 - recall: 0.8603 - val_accuracy: 0.7174 - val_loss: 0.5666 - val_precision: 0.5218 - val_recall: 0.3848\n",
            "Epoch 229/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8624 - loss: 0.3273 - precision: 0.8846 - recall: 0.8637 - val_accuracy: 0.7227 - val_loss: 0.5731 - val_precision: 0.5377 - val_recall: 0.3581\n",
            "Epoch 230/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8623 - loss: 0.3305 - precision: 0.8861 - recall: 0.8615 - val_accuracy: 0.7238 - val_loss: 0.5538 - val_precision: 0.5430 - val_recall: 0.3398\n",
            "Epoch 231/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8648 - loss: 0.3314 - precision: 0.8866 - recall: 0.8660 - val_accuracy: 0.7250 - val_loss: 0.5637 - val_precision: 0.5451 - val_recall: 0.3519\n",
            "Epoch 232/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8642 - loss: 0.3283 - precision: 0.8891 - recall: 0.8618 - val_accuracy: 0.7087 - val_loss: 0.5753 - val_precision: 0.5013 - val_recall: 0.4171\n",
            "Epoch 233/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8636 - loss: 0.3304 - precision: 0.8849 - recall: 0.8658 - val_accuracy: 0.7166 - val_loss: 0.5641 - val_precision: 0.5211 - val_recall: 0.3618\n",
            "Epoch 234/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.3290 - precision: 0.8838 - recall: 0.8653 - val_accuracy: 0.7213 - val_loss: 0.5623 - val_precision: 0.5303 - val_recall: 0.3969\n",
            "Epoch 235/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8640 - loss: 0.3302 - precision: 0.8853 - recall: 0.8660 - val_accuracy: 0.7200 - val_loss: 0.5540 - val_precision: 0.5259 - val_recall: 0.4167\n",
            "Epoch 236/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8600 - loss: 0.3351 - precision: 0.8801 - recall: 0.8645 - val_accuracy: 0.7066 - val_loss: 0.5773 - val_precision: 0.4970 - val_recall: 0.3936\n",
            "Epoch 237/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.3318 - precision: 0.8863 - recall: 0.8591 - val_accuracy: 0.7229 - val_loss: 0.5582 - val_precision: 0.5349 - val_recall: 0.3900\n",
            "Epoch 238/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8654 - loss: 0.3240 - precision: 0.8880 - recall: 0.8657 - val_accuracy: 0.7209 - val_loss: 0.5621 - val_precision: 0.5355 - val_recall: 0.3317\n",
            "Epoch 239/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8625 - loss: 0.3297 - precision: 0.8875 - recall: 0.8601 - val_accuracy: 0.7310 - val_loss: 0.5475 - val_precision: 0.5567 - val_recall: 0.3863\n",
            "Epoch 240/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8613 - loss: 0.3334 - precision: 0.8836 - recall: 0.8627 - val_accuracy: 0.7194 - val_loss: 0.5814 - val_precision: 0.5262 - val_recall: 0.3900\n",
            "Epoch 241/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8619 - loss: 0.3294 - precision: 0.8856 - recall: 0.8614 - val_accuracy: 0.7177 - val_loss: 0.5685 - val_precision: 0.5234 - val_recall: 0.3687\n",
            "Epoch 242/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 0.3265 - precision: 0.8881 - recall: 0.8637 - val_accuracy: 0.7273 - val_loss: 0.5534 - val_precision: 0.5525 - val_recall: 0.3468\n",
            "Epoch 243/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8663 - loss: 0.3236 - precision: 0.8908 - recall: 0.8639 - val_accuracy: 0.7230 - val_loss: 0.5706 - val_precision: 0.5341 - val_recall: 0.4010\n",
            "Epoch 244/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8624 - loss: 0.3277 - precision: 0.8831 - recall: 0.8657 - val_accuracy: 0.7205 - val_loss: 0.5664 - val_precision: 0.5277 - val_recall: 0.4083\n",
            "Epoch 245/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8655 - loss: 0.3279 - precision: 0.8909 - recall: 0.8622 - val_accuracy: 0.7095 - val_loss: 0.5750 - val_precision: 0.5031 - val_recall: 0.4204\n",
            "Epoch 246/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8641 - loss: 0.3255 - precision: 0.8863 - recall: 0.8652 - val_accuracy: 0.7236 - val_loss: 0.5655 - val_precision: 0.5445 - val_recall: 0.3274\n",
            "Epoch 247/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8640 - loss: 0.3282 - precision: 0.8919 - recall: 0.8579 - val_accuracy: 0.7219 - val_loss: 0.5678 - val_precision: 0.5363 - val_recall: 0.3519\n",
            "Epoch 248/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8610 - loss: 0.3326 - precision: 0.8828 - recall: 0.8630 - val_accuracy: 0.7249 - val_loss: 0.5687 - val_precision: 0.5487 - val_recall: 0.3259\n",
            "Epoch 249/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8648 - loss: 0.3245 - precision: 0.8914 - recall: 0.8600 - val_accuracy: 0.7205 - val_loss: 0.5624 - val_precision: 0.5355 - val_recall: 0.3230\n",
            "Epoch 250/250\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8632 - loss: 0.3293 - precision: 0.8849 - recall: 0.8650 - val_accuracy: 0.7227 - val_loss: 0.5554 - val_precision: 0.5358 - val_recall: 0.3753\n"
          ]
        }
      ],
      "source": [
        "model_nn = get_model_simple(input_shape=train_data.shape[1:])\n",
        "model_nn.summary()\n",
        "compile_model_simple(model_nn)\n",
        "history_nn = train_model_simple(model_nn, train_data, train_labels_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPYmyqKxFyRA"
      },
      "source": [
        "**MATRIZ DE CONFUSION**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threshold a 0.3 para no ser tan duros con los casos de \"yes\" si no, darle mas oportunidad al modelo de darnos resultados cuando no esta convencido."
      ],
      "metadata": {
        "id": "WJsHm99k6uUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "akatAMjDF4J-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "26a16912-ebd6-4c89-c05f-c2066998943b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "predictions_probabilities = model_nn.predict(test_data)\n",
        "predictions = (predictions_probabilities > 0.3).astype(int)\n",
        "predictions = predictions.flatten()\n",
        "\n",
        "cm = confusion_matrix(test_labels_target, predictions)\n",
        "labels = enc.classes_\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P4ihSCn4IM2"
      },
      "source": [
        "De la prediccion:\n",
        "Precision: Cuantos eran realmente positivos\n",
        "Racall: De los TP, cuantos detecto el modelo\n",
        "F1 Score: Media entre Precision y Recall (para datos desbalanceados)\n",
        "Support: Cuantos yes y no había\n",
        "\n",
        "Resumen: conocer si el modelo que tiene datos desbalanceados, realmente esta detectando de manera correcta la clase menos frecuente (yes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "UuXlv8Xt320V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b84eef5-f2d9-4a20-9b41-56bd34bff97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.83      0.67      0.74      6623\n",
            "         yes       0.46      0.68      0.55      2731\n",
            "\n",
            "    accuracy                           0.67      9354\n",
            "   macro avg       0.65      0.67      0.64      9354\n",
            "weighted avg       0.72      0.67      0.68      9354\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels_target, predictions, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhbb-kj5EZn_"
      },
      "source": [
        "**GUARDAR MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "I5RIeRVfEcyP"
      },
      "outputs": [],
      "source": [
        "model_nn.save(\"banksell.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE09RFbZV7QaiBRBxBE1Nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}