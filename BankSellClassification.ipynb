{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP6Y2BWe9iDrXcGCM6gDif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisseDB/MachineLearning-BankAnalyses/blob/main/BankSellClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Wn406ZuCFC0R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# para el one hot encoder\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFV056K7Fdc9",
        "outputId": "3fcb7380-9b77-437f-c95c-0d5f0116d5b7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accedemos tanto al modelo como al encoder para los inputs del usuario, de tal forma que puedan ser transfromados a binario"
      ],
      "metadata": {
        "id": "f5sWueSTaLCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/BankData/banksell.keras\")\n",
        "oneHotEncoder = joblib.load(\"/content/drive/MyDrive/BankData/onehotencoder.pkl\")"
      ],
      "metadata": {
        "id": "Dt6_Yy08G7Jh"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columnas necesarias\n",
        "- needEncoder, son aquellas que necesitan pasar por el oneHotEncoder\n",
        "- noEncoder, ya son numericas, por lo tanto, no es necesaria una transformacion"
      ],
      "metadata": {
        "id": "yP3tWhI-aWG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['age', 'marital', 'education', 'default', 'loan', 'duration']\n",
        "needEncoder = ['marital', 'education', 'default', 'loan']\n",
        "noEncoder = ['age', 'duration']"
      ],
      "metadata": {
        "id": "TedZ8D45UuSB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si el input necesita encoder, lo guardamos tal cual se recibe, pero, si no necesita encoder, lo guardamos como un float"
      ],
      "metadata": {
        "id": "hPO2x4wVd86F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Age -> Edad -> Input numerico\n",
        "*   Maritial -> Estado civil -> single, married, divorced (valido para widowed) o unknown\n",
        "* Education -> Nivel de estudios -> primary, secondary, tertiary o unknown\n",
        "* Default -> ¿Tiene mal historial con deudas no pagadas? -> Yes o No\n",
        "* Loan -> ¿Tiene deudas pendientes? -> Yes o No\n",
        "* Duration -> Duración de la llamada -> Minutoshas  \n",
        "\n"
      ],
      "metadata": {
        "id": "GJFNcmJ6bTKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = {}\n",
        "print(\"Plese enter the costumer information:\")\n",
        "\n",
        "for column in columns:\n",
        "  if column in needEncoder:\n",
        "    userInput[column] = input(f\"{column}: \")\n",
        "  else:\n",
        "    userInput[column] = float(input(f\"{column}: \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krXfnOfOG4Ox",
        "outputId": "0cbcf4d2-78f7-44c4-a628-65cec93d5b83"
      },
      "execution_count": 87,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plese enter the costumer information:\n",
            "age: 23\n",
            "marital: SINGLE\n",
            "education: TERTIARY\n",
            "default: NO\n",
            "loan: NO\n",
            "duration: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el dataframe con los datos del usuario que son los que se van a predecir con ayuda del modelo"
      ],
      "metadata": {
        "id": "jE45t4Ceeftx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(userInput, index=[0])\n"
      ],
      "metadata": {
        "id": "mKd4dxtYT6Oy"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A las columnas con inputs que necesitan el One Hot Encoder, se lo aplicamos, para despues, ahora si, juntar ambas columnas y tener el dataframe completo"
      ],
      "metadata": {
        "id": "czf7hyzheg6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = oneHotEncoder.transform(df[needEncoder])\n",
        "encoded_df = pd.DataFrame(encoded, columns = oneHotEncoder.get_feature_names_out())\n",
        "concat = pd.concat([encoded_df, df[noEncoder].reset_index(drop=True)], axis=1)"
      ],
      "metadata": {
        "id": "AcWOX_WTVDu-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le pasamos los datos al modelo para que nos de una predicción de acuerdo a los datos que le hemos mandado"
      ],
      "metadata": {
        "id": "8od3U2zZfLU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(concat.to_numpy())\n",
        "prob = pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv1wFsUeVdBB",
        "outputId": "f172287a-e0cf-4a07-8e71-e621e773ae30"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"El cliente SÍ aceptará la tarjeta\" if prob >= 0.5 else \"El cliente NO aceptará la tarjeta\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHmbxwl0V5I-",
        "outputId": "2fca283e-0af0-4554-c0c0-22accabb897e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El cliente SÍ aceptará la tarjeta\n"
          ]
        }
      ]
    }
  ]
}